<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Neural Radiance Fields (NeRF) | Damanpreet  Singh</title>
    <meta name="author" content="Damanpreet  Singh">
    <meta name="description" content="&lt;ul&gt; &lt;li&gt;In this project, I implemented 3D volume and surface rendering pipelines, using NeRF&lt;/li&gt; &lt;li&gt;The project was implemented in Python3. I also extended the baseline to improve surface reconstruction with realistic lights using Phong Relighting and improved radiance computation using heiraarchical point sampling &lt;/li&gt;  &lt;/ul&gt;">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/website_icon2.png">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://dpsingh.github.io/projects/1_project/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Damanpreet </span>Singh</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">Repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">Resume</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Neural Radiance Fields (NeRF)</h1>
            <p class="post-description"></p>
<ul> <li>In this project, I implemented 3D volume and surface rendering pipelines, using NeRF</li> <li>The project was implemented in Python3. I also extended the baseline to improve surface reconstruction with realistic lights using Phong Relighting and improved radiance computation using heiraarchical point sampling </li>  </ul>
          </header>

          <article>
            <p>This project is an implementation of the ground-breaking 3D volumetric reconstruction work by Ben Mildenhall, <a href="https://www.matthewtancik.com/nerf" rel="external nofollow noopener" target="_blank">NeRF</a> and was written in Python3 and made use of the following libraries- PyTorch, NumPy, Hydra, and Matplotlib. This project was implemented as a part of my Spring 2023 course at CMU, <a href="https://learning3d.github.io/" rel="external nofollow noopener" target="_blank">Learnig for 3D Vision</a>, taught by <a href="http://shubhtuls.github.io/" rel="external nofollow noopener" target="_blank">Prof. Shubham Tulsiani</a>.</p>

<h1 id="volume-reconstruction">Volume Reconstruction</h1>

<h3 id="ray-sampling">Ray Sampling</h3>
<p>First part in the process to generate a NeRF is to desgn a ray sampler, capable of producing 3D rays in the world space, from a given set of image co-ordinates. This is done by generating a normalized meshgrid over the image dimensions, using <strong><em>Pytorch.meshgrid</em></strong> and using this to project rays into 3D space. These rays, currently in camera space, are then transformed into world space using appropriate camera extrinsics. The image below shows an exmaple of a meshgrid and the resulting rays visualized from the origin location.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/projects/l3d_projects/nerf/coord_grid.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Image Coordinates" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/projects/l3d_projects/nerf/coord_rays.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Image Rays" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    The left figure shows a visualization of the image coordiantes. The right image shows a visualization of the projected rays from the origin
</div>

<h3 id="point-sampling">Point Sampling</h3>
<p>The second step involves sampling points, using the rays generated in the previous section. Points are sampled along the rays generated, at stratified intervals, up until a maximum threshold. This gives us a semicircular point cloud of samples along the rays, which can be seen visualized in the image below.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-0 mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/projects/l3d_projects/nerf/points_sampled.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Sampled Points" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Sampled points in a bundle of rays
</div>

<h3 id="volume-rendering">Volume Rendering</h3>
<p>Now, a volume rendering function is designed, which would take <em>input</em> the <em>sampled points</em> defined in the previous section, and an <em>implicit volume function</em> for an object and use the transmittance equations defined below to produce a volume rendering for that object. The equations can be underestood from the figure below which shows a point sampling inside an object. The first equation is a recursive equation, that calulates the emission (color) for the segment <strong><em>i</em></strong>, shown in red below. The second equation calculates the transmittance of this segment with respect to the point-of-view (eye in the figure), based on the object absorption and emission coefficients. Please visit <a href="https://taiya.github.io/pubs/tagliasacchi2022volume.pdf" rel="external nofollow noopener" target="_blank">this page</a> for detailed explanation on transmittance calculations in volume rendering</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-8 mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/projects/l3d_projects/nerf/transmittance_fig.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>

<font size="+2">
$$ L(x,w)= \sum_{i=1}^{N} T(x, x_{t_i})(1 - e^{-\sigma_{t_{i}} \Delta t_i }) L_e(x_{t_i}, w) $$

$$ T(x, x_{t_i}) = T(x, x_{t_{i-1}})e^{-(\sigma_{t_{i-1}} \Delta t_{i-1})} $$
</font>

<p>A sample rendering using this renderer, for a cube is shown in the animation below.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-0 mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/projects/l3d_projects/nerf/cube_render.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Cube render using the Volume Renderer
</div>

<h3 id="designing-nerf">Designing NeRF</h3>
<p>A neural radiance field is a neural network used to approximate the implicit function for any given object. It is trained on multiple images of this object and is capable of producing continuous volume renders. The multi-layered perceptron (MLP) network used by me for this purpose is shown below</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-8 mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/projects/l3d_projects/nerf/nerf_mlp.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    MLP used for NeRF
</div>

<p>This MLP was trained on the multi-view images of a bulldozer. The hyperparamters used for this training are listed in the table below. The results of the volume rendering can be seen in the image below.</p>

<div class="row justify-content-sm-center">
    <table style="shrink;">
    <tr>
        <th>Hyperparameter</th>
        <th>Value</th>
    </tr>
    <tr>
        <td>Learning rate</td>
        <td>1e-4</td>
    </tr>
    <tr>
        <td>Epochs</td>
        <td>250</td>
    </tr>
    <tr>
        <td>Batch Size</td>
        <td>1024</td>
    </tr>
    <tr>
        <td>Number of Sampled Rays</td>
        <td>32768</td>
    </tr>
    <tr>
        <td>Number of Points per Ray</td>
        <td>128</td>
    </tr>
    <tr>
        <td>Image Resolution</td>
        <td>600X600</td>
    </tr>
    </table>
</div>
<p><br></p>
<div class="row justify-content-sm-center">
    <div class="col-sm-0 mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/projects/l3d_projects/nerf/crane_highres.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    NeRF volume rendering results for bulldozer
</div>

<div class="row justify-content-sm-center">
    <div class="col-sm-4 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/projects/l3d_projects/nerf/progress/1.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/projects/l3d_projects/nerf/progress/2.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/projects/l3d_projects/nerf/progress/4.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    NeRF progression through training. From left to right - 50 epochs, 100 epochs, 250 epochs
</div>

<h1 id="surface-reconstruction">Surface Reconstruction</h1>

<p>The implementation of NeRF was extended to include Surface Reconstruction, using Neural Implicit Surfaces. Here, we implement a Neural SDF which is basically an approximation of the <a href="https://en.wikipedia.org/wiki/Signed_distance_function" rel="external nofollow noopener" target="_blank">signed distance function</a> (SDF) for any object using a neural network. SDF is the signed orthogonal distance of a given point to the boundary of an object. The sign determines whether the point lies inside or outside the boundary. The function has positive values for points inside the boundary.</p>

          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Damanpreet  Singh. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
